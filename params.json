{"name":"Numba-nextgen","tagline":"","body":"% flypy - The core language ideas\r\n% \r\n% \r\n\r\nThis document describes the core flypy language, which is designed to\r\ngenerate efficient code for general, pythonic code. It will allow us to\r\nimplement most of the features that currently reside in the compiler\r\ndirectly in a runtime. On top of this small core language we can write\r\nmore advanced features such as subtype polymorphism through method\r\ntables.\r\n\r\nI believe we need the following features:\r\n\r\n> -   Methods on user-defined types with specified representations\r\n>     (structs or otherwise)\r\n>\r\n>     > -   Careful control over allocation and mutability\r\n>\r\n> -   Polymorphism: Generic functions, subtyping, overloading\r\n> -   User-defined typing rules\r\n> -   Careful control over inlining, unrolling and specialization\r\n> -   Extension of the code generator\r\n>\r\nSupport for multi-stage programming would be nice, but is considered a\r\nbonus and deferred to external tools like macropy or mython for now. The\r\ncontrol over optimizations likely provides enough functionality to\r\ngenerate good code.\r\n\r\nThis describes a closed environment with an optionally static, inferred,\r\nlanguage. Static typing will help provide better error messages, and can\r\nprevent inintended use.\r\n\r\nPolymorphism is provided through:\r\n\r\n> -   generic functions\r\n> -   multiple dispatch\r\n> -   subtyping (\"python classes\")\r\n> -   coercion\r\n\r\nThis language's goals are ultimate control over performance, and a\r\nlanguage with a well-defined and easily understood subset for the GPU.\r\n\r\nThis language is inspired by the following languages: Rust, Terra,\r\nRPython, Julia, Parakeet, mypy, copperhead. It focusses on static\r\ndispatch flexibility, allowing specialization for static dispatch, or\r\nallowing generating more generic machine code with runtime dispatch.\r\nLike RPython, it will further allow specialization on constant values,\r\nwhich allows generic code to turn into essentially static code, enabling\r\npartial evaluation opportunities as well as improved type inference.\r\n\r\nWhat we want in our language is full control over specialization and\r\nmemory allocation, and easily-understood semantics for what works on the\r\nGPU and what doesn't. The following sections will detail how the above\r\nfeatures will get us there.\r\n\r\n1. User-defined Types\r\n=====================\r\n\r\nWe want to support user-defined types with:\r\n\r\n> -   control over representation\r\n> -   (special) methods\r\n> -   control over mutability\r\n> -   control over stack- vs gc-allocation\r\n\r\nUser-defined types do not support inheritance, which is left to a\r\nruntime implementation. This means that the callees of call-sites are\r\nstatic, and can be called directly. This further means they can be\r\ninlined (something we will exploit).\r\n\r\nThis means that we can even write the most performance-critical parts of\r\nour runtime in this way. The compiler needs to support the following\r\ntypes natively:\r\n\r\n> -   int\r\n> -   float\r\n> -   pointer\r\n> -   struct (with optional methods and properties)\r\n> -   union\r\n> -   array (constant size)\r\n\r\nAnything else is written in the runtime:\r\n\r\n> -   range\r\n> -   complex\r\n> -   array\r\n> -   string/unicode\r\n> -   etc\r\n\r\nThis means we can easily experiment with different data representations\r\nand extend functionality. For instance we can wrap and override the\r\nnative integer multiply to check for overflow, and raise an exception or\r\nissue a warning, or convert to a BigInt.\r\n\r\nRepresentation\r\n--------------\r\n\r\nType representation can be specified through a type 'layout':\r\n\r\n```python\r\n@jit\r\nclass Array(object):\r\n    layout = Struct([('data', 'Char *')])\r\n```\r\n\r\nMutability and Allocation\r\n-------------------------\r\n\r\nEach individual field can be specified to be immutable, or all can be\r\nspecified immutable through a decorator:\r\n\r\n```python\r\n@jit(immutable=True)\r\nclass Array(object):\r\n    ...\r\n```\r\n\r\nIf all fields are immutable, the object can be stack allocated. Unless\r\nmanually specified with `stack=True`, the compiler is free to decide\r\nwhere to allocate the object. This decision may differ depending on the\r\ntarget (cpu or gpu).\r\n\r\nThe `Array` above can be stack-allocated since its fields are immutable\r\n-even though the contained data may not be.\r\n\r\nIf data is mutable, it is allocated on the heap. This means that\r\nallocation of such an object is incompatible with a GPU code generator.\r\nHence, data structures like Arrays must be passed in from the host, and\r\nthings like Lists are not supported. However, one can write a List\r\nimplementation with static size that supports appending a bounded number\r\nof objects.\r\n\r\nWe disallow explicit stack allocation for mutable types for the\r\nfollowing reason:\r\n\r\n```python\r\nx = mutable() # stack allocate\r\ny = x         # copy x into y\r\ny.value = 1   # update y.value, which does not affect x.value\r\n```\r\n\r\nTo make this work one would need to track the lifetimes of the object\r\nitself and all the variables the object is written into, at which point\r\nwe defer you to the Rust programming language. We leave stack allocation\r\nof mutable objects purely as a compile-time optimization.\r\n\r\nDestructors\r\n-----------\r\n\r\nDestructors are supported only for heap-allocated types, irrespective of\r\nmutability. If a \\_\\_del\\_\\_ method is implemented, the object will be\r\nautomatically heap-allocated (unless escape analysis can say otherwise).\r\n\r\nOwnership\r\n---------\r\n\r\nOwnership is tied to mutability:\r\n\r\n> -   Data is owned when (recursively) immutable\r\n> -   Data is shared when it, or some field is mutable (recursively)\r\n\r\nOwned data may be send over a channel to another thread or task. Shared\r\ndata cannot be send, unless explicitly marked as a safe operation:\r\n\r\n    channel.send(borrow(x))\r\n\r\nThe user must guarantee that 'x' stays alive while it is consumed. This\r\nis useful for things like parallel computation on arrays.\r\n\r\nType Parameters\r\n---------------\r\n\r\nUser-defined types are parameterizable:\r\n\r\n```python\r\n@jit('Array[Type dtype, Int ndim]')\r\nclass Array(object):\r\n    ...\r\n```\r\n\r\nParameters can be types or values of builtin type int. This allows\r\nspecialization for values, such as the dimensionality of an array:\r\n\r\n```python\r\n@jit('Array[Type dtype, Int ndim]')\r\nclass Array(object):\r\n\r\n    layout = Struct([('data', 'Char *'), ('strides', 'Tuple[Int, ndim]')])\r\n\r\n    @signature('Tuple[Int, ndim] -> T')\r\n    def __getitem__(self, indices):\r\n        ...\r\n```\r\n\r\nThis specifies that we take a `Tuple` of `Int`s an size `ndim` as\r\nargument, and return an item of type `T`. The `T` and `ndim` are\r\nresolved as type parameters, which means they specify concrete types in\r\nthe method signature.\r\n\r\nThe type can now be used as follows:\r\n\r\n```python\r\nmyarray = Array[Double, 2]()\r\n```\r\n\r\nThis will mostly appear in (flypy) library code, and not in user-written\r\ncode, which uses higher-level APIs that ultimately construct these\r\ntypes. E.g.:\r\n\r\n```python\r\n@overload(np.ndarray)\r\ndef typeof(array):\r\n    return Array[typeof(array.dtype), array.ndim]\r\n\r\n@overload(np.dtype)\r\ndef typeof(array):\r\n    return { np.double: Double, ...}[array.dtype]\r\n```\r\n\r\n2. Polymorphism\r\n===============\r\n\r\nSupported forms of polymorphism are generic functions, overloading and\r\nsubtyping.\r\n\r\nGeneric Functions and Subtyping\r\n-------------------------------\r\n\r\nFor additional details, including implementation details, see\r\n:ref:\\`polymorphism\\`.\r\n\r\nGeneric functions allow code to operate over multiple types\r\nsimultaneously. For instance, we can type the \\`map\\` function,\r\nspecifying that it maps values of type \\`a\\` to type \\`b\\`.\r\n\r\n```python\r\n@jit('(a -> b) -> [a] -> [b]')\r\ndef map(f, xs):\r\n    ...\r\n```\r\n\r\nType variables may be further constrained by sets of types or by\r\nclasses, e.g.:\r\n\r\n```python\r\n@jit('Array[A : Float[nbits]] -> A')\r\ndef sum(xs):\r\n    ...\r\n```\r\n\r\nwhich allows `sum` to accept any array with floating point numbers or\r\nany subtype is Float. By default, typed code will accept subtypes, e.g.\r\nif we have a typed argument `A`, then we will also accept a subtype `B`\r\nfor that argument.\r\n\r\nWith parameterized types, we have to be more careful. By default, we\r\nallow only invariant parameters, e.g. `B <: A` does not imply\r\n`C[B] <: C[A]`. That is, even though `B` may be a subtype of `A`, a\r\nclass `C` parameterized by `B` is not a subtype of class `C`\r\nparameterized by `A`. In generic functions, we may however indicate\r\nvariance using `+` for \\`covariance\\` and `-` for \\`contra-variance\\`:\r\n\r\n```python\r\n@jit('Array[A : +Number] -> A')\r\ndef sum(array):\r\n    ...\r\n```\r\n\r\nThis indicates we will accept an array of `Number`s, or any subtypes of\r\n`Number`. This is natural for algorithms that read data, e.g if you can\r\nread objects of type `A`, you can also read objects of subtype `B` of\r\n`A`.\r\n\r\nHowever, if we were writing objects, this would break! Consider the\r\nfollowing code:\r\n\r\n```python\r\n@jit('Array[T : +A] -> Void')\r\ndef write(array):\r\n    array[0] = B()\r\n```\r\n\r\nHere we write an `B`, which clearly satisfies being an `A`. However, if\r\nwe also have `C <: B`, and if we provide `write` with a `Array[C]`, we\r\ncannot write a `B` into this array!\r\n\r\nInstead, this code must have a contra-variant parameter, that is, it may\r\naccept an array of `B` and an array of any super-type of `B`.\r\n\r\nGeneric functions may be specialized or generic, depending on the\r\ndecorator used.\r\n\r\nOverloading and Multiple-dispatch\r\n---------------------------------\r\n\r\nThese mechanisms provide compile-time selection for our language. It is\r\nrequired to support the compiled `convert` from section 3, and necessary\r\nfor many implementations, e.g.:\r\n\r\n```python\r\n@jit('a : integral -> a')\r\ndef int(x):\r\n    return x\r\n\r\n@jit('String -> Int')\r\ndef int(x):\r\n    return parse_int(x)\r\n```\r\n\r\n3. User-defined Typing Rules\r\n============================\r\n\r\nI think Julia does really well here. Analogously we define three\r\nfunctions:\r\n\r\n> -   typeof(pyobj) -\\> Type\r\n> -   convert(Type, Value) -\\> Value\r\n> -   unify(Type, Type) -\\> Type\r\n\r\nThe `convert` function may make sense as a method on the objects\r\ninstead, which is more pythonic, e.g. `__convert__`. `unify` does not\r\nreally make sense as a method since it belongs to neither of the two\r\narguments.\r\n\r\nUnify takes two types and returns the result type of the given types.\r\nThis result type can be specified by the user. For instance, we may\r\ndetermine that `unify(Int, Float)` is `Union(Int, Float)`, or that it is\r\n`Float`. The union will give the same result as Python would, but it is\r\nalso more expensive in the terms of the operations used on it (and\r\npotentially storage capacity). Unify is used on types only at control\r\nflow merge points.\r\n\r\nA final missing piece are a form of ad-hoc polymophism, namely\r\ncoercions. This is tricky in the presence of overloading, where multiple\r\ncoercions are possible, but only a single coercion is preferable. E.g.:\r\n\r\n```python\r\n@overload('Float32 -> Float32 -> Float32')\r\ndef add(a, b):\r\n    return a + b\r\n\r\n@overload('Complex64 -> Complex64 -> Complex64')\r\ndef add(a, b):\r\n    return a + b\r\n```\r\n\r\nWhich implementation is `add(1, 2)` supposed to pick, `Int` freely\r\ncoerces to both `Float32` and `Complex64`? Since we don't want built-in\r\ncoercion rules, which are not user-overridable or extensible, we need\r\nsome sort of coercion function. We choose a function\r\n`coercion_distance(src_type, dst_type)` which returns the supposed\r\ndistance between two types, or raises a TypeError. Since this is not\r\ncompiled, we decide to not make it a method of the source type.\r\n\r\n```python\r\n@overload(Int, Float)\r\ndef coercion_distance(int_type, float_type):\r\n    return ...\r\n```\r\n\r\nThese functions are used at compile time to determine which conversions\r\nto insert, or whether to issue typing errors.\r\n\r\n4. Optimization and Specialization\r\n==================================\r\n\r\nWe need to allow careful control over optimizations and code\r\nspecialization. This allows us to use the abstractions we need, without\r\npaying them if we know we can't afford it. We propose the following\r\nintrinsics exposed to users:\r\n\r\n> -   `for x in unroll(iterable): ...`\r\n> -   `@specialize.arg(0)`\r\n\r\nUnrolling\r\n---------\r\n\r\nThe first compiler intrinsic allows unrolling over constant iterables.\r\nFor instance, the following would be a valid usage:\r\n\r\n```python\r\nx = (1, 2, 3)\r\nfor i in unroll(x):\r\n    ...\r\n```\r\n\r\nAn initial implementation will likely simply recognize special container\r\ntypes (Tuple, List, etc). Later we may allow arbitrary (user-written!)\r\niterables, where the result of `len()` must be ultimately constant\r\n(after inlining and register promotion).\r\n\r\nSpecialization\r\n--------------\r\n\r\nThe ability to specialize on various things, similar to specialization\r\nin rpython (`rpython/rlib/objectmodel.py`).\r\n\r\nThese decorators should also be supported as extra arguments to\r\n`@signature` etc.\r\n\r\n5. Extension of the Code Generator\r\n==================================\r\n\r\nWe can support an `@opaque` decorator that marks a function or method as\r\n\"opaque\", which means it must be resolved by the code generator. A\r\ndecorator `@codegen(thefunc)` registers a code generator function for\r\nthe function or method being called:\r\n\r\n```python\r\n@jit('Int[Int size]')\r\nclass Int(object):\r\n    @opague('Int -> Int', eval_if_const=True)\r\n    def __add__(self, other):\r\n        return a + b\r\n\r\n@codegen(Int.__add__)\r\ndef emit_add(func, argtypes):\r\n    # return a new typed function...\r\n```\r\n\r\nConclusion\r\n==========\r\n\r\nThe mechanisms above allow us to easily evaluate how code will be\r\ncompiled, and asses the performance implications. Furthermore, we can\r\neasily see what is GPU incompatible, i.e. anything that:\r\n\r\n> -   uses CFFI (this implies use of Object, which is implemented in\r\n>     terms of CFFI)\r\n> -   uses specialize.generic()\r\n> -   allocates anything mutable\r\n\r\nEverything else should still work.\r\nPolymorphism\r\n============\r\n\r\nAs mentioned in :ref:\\`core\\`, we support the following forms of\r\npolymorphism:\r\n\r\n> -   generic functions\r\n> -   multiple dispatch\r\n> -   subtyping (\"python classes\")\r\n> -   coercion\r\n\r\nThis section discusses the semantics and implementation aspects, and\r\ngoes into detail about the generation of specialized and generic code.\r\n\r\nSemantics\r\n---------\r\n\r\nA generic function is a function that abstracts over the types of its\r\nparameters. The simplest function is probably the identity function,\r\nwhich returns its argument unmodified:\r\n\r\n```python\r\n@jit('a -> a')\r\ndef id(x):\r\n    return x\r\n```\r\n\r\nThis function can act over any value, irregardless of its type.\r\n\r\nType \\`A\\` is a subtype of type \\`B\\` if it is a python subclass.\r\n\r\nSpecialization and Generalization\r\n---------------------------------\r\n\r\nIn flypy-lang we need the flexibility to choose between highly\r\nspecialized and optimized code, but also more generic, modular, code.\r\nThe reason for the latter is largely compilation time and memory use\r\n(i.e. avoiding \"code bloat\"). But it may even be that code is\r\ndistributed or deployed pre-compiled, without any source code (or\r\ncompiler!) available.\r\n\r\nWe will first explain the implementation of the polymophic features\r\nbelow in a specialized setting, and then continue with how the same\r\nfeatures will work when generating more generic code. We then elaborate\r\non how these duals can interact.\r\n\r\n### Specialized Implementation\r\n\r\nOur polymorphic features can be implemented by specializing everything\r\nfor everything.\r\n\r\nFor generic functions, we \"monomorphize\" the function for the cartesian\r\nproduct of argument types, and do so recursively for anything that it\r\nuses in turn.\r\n\r\nWe also specialize for subtypes, e.g. if our function takes a type\r\n\\`A\\`, we can also provide subtype \\`B\\`. This allows us to always\r\nstatically know the receiver of a method call, allowing us to\r\ndevirtualize them.\r\n\r\nFinally, multiple-dispatch is statically resolved, since all input types\r\nto a call are known at compile time. This is essentially overloading.\r\n\r\n### Generic Implementation\r\n\r\nThere are many ways to generate more generic code. Generally, to\r\ngenerate generic code for polymorphic code, we need to represent data\r\nuniformly. We shall do this through pointers. We pack every datum into a\r\ngeneric structure called a box, and we pass the boxes around. In order\r\nto implement on operation on the box, we need to have some notion of\r\nwhat the datum in this box \"looks like\". If we know nothing about the\r\ncontents of a box, all we can do is pass it around, and inspect its\r\ntype.\r\n\r\nWe support generic code through the `@gjit` decorator ('generic jit'),\r\nwhich can annotate functions or entire classes, turning all methods into\r\ngeneric methods.\r\n\r\nWe define the following semantics:\r\n\r\n> -   Inputs are boxed, unless fully typed\r\n>\r\n>     > -   This guarantees that we only have to generate a single\r\n>     >     implementation of the function\r\n>\r\n> -   Boxes are automatically unboxed to specific types with a runtime\r\n>     type check, unless a bound on the box obsoletes the check\r\n>\r\n>     > -   This allows interaction with more specialized code\r\n>\r\n> -   Bounds on type variables indicate what operations are allowed over\r\n>     the instances\r\n>\r\n> -   Subtyping trumps overloading\r\n>\r\nFurther, if we have boxes with unknown contents, they must match the\r\nconstraints of whereever they are passed exactly. For instance:\r\n\r\n```python\r\n@jit('List[a] -> a -> void')\r\ndef append(lst, x):\r\n    ...\r\n\r\n@jit('List[a] -> b -> void')\r\ndef myfunc(lst, x):\r\n    append(lst, x)  # Error! We don't know if type(a) == type(b)\r\n```\r\n\r\nIssuing an error in such situations allows us to avoid runtime type\r\nchecks just for passing boxes around. The same goes for return types,\r\nthe inferred bounds must match any declared bounds or a type error is\r\nissued.\r\n\r\nWe implement subtyping through virtual method tables, similar to C++,\r\nCython and a wide variety of other languages. To provide varying arity\r\nfor multiple-dispatch and overriding methods, arguments must be packed\r\nin tuples or arrays of pointers along with a size. Performing dispatch\r\nis the responsibility of the method, not the caller, which eliminates an\r\nindirection and results only in slower runtime dispatch where needed.\r\n\r\nFinally, multiple dispatch is statically resolved if possible, otherwise\r\nit performs a runtime call to a generic function that resolves the right\r\nfunction given the signature object, a list of overloads and the runtime\r\narguments.\r\n\r\nCoercion is supported only to unbox boxes with a runtime check if\r\nnecessary.\r\n\r\n#### Bounds\r\n\r\nUsers may specify type bounds on objects, in order to provide operations\r\nover them. For instance, we can say:\r\n\r\n```python\r\n@jit('a <: A[] -> a')\r\ndef func(x):\r\n    ...\r\n```\r\n\r\nAlternatively, one could write 'A[] -\\> A[]', which has a subtly\r\ndifferent meaning if we put in a subtype \\`B\\` of class \\`A\\` (instead\r\nof getting back a \\`B\\`, we'd only know that we'd get back an object of\r\ntype \\`A\\`).\r\n\r\nWe realize that we don't want to be too far removed from python\r\nsemantics, and in order to compare to objects we don't want to inherit\r\nfrom a say, a class \\`Comparable\\`. So by default we implement the Top\r\nin the type lattice, which we know as \\`object\\`. This has default\r\nimplementations for most special methods, raising a NotImplementedError\r\nwhere implementation is not sensible.\r\n\r\nInteraction between Specialized and Generic Code\r\n------------------------------------------------\r\n\r\nIn order to understand the interaction between specialized and generic\r\ncode, we explore the four bridges between the two:\r\n\r\n### Generic \\<-\\> Generic\r\n\r\nPass around everything in type-tagged boxes, retain pointer to vtable in\r\nobjects. If there are fully typed parameters, allow those to be passed\r\nin unboxed, and generate a wrapper function that takes those arguments\r\nas boxes and unboxes them.\r\n\r\n### Generic \\<-\\> Specialized\r\n\r\nGenerally generic code can call specialized functions or methods of\r\nobjects of known type directly. Another instance of this occurs when\r\ninstances originate from specialized classes. Consider populating a list\r\nof an int, string and float. Generic wrappers are generated around the\r\nspecialized methods, and a vtable is populated. The wrappers are\r\nimplemented as follows:\r\n\r\n```python\r\n@gjit('a -> a -> bool')\r\ndef wrapper_eq(int_a, int_b):\r\n    return box(specialized_eq(unbox(a), unbox(b)))\r\n```\r\n\r\nWe further need to generate properties that box specialized instance\r\ndata on read, and unbox boxed values on write.\r\n\r\n### Specialized \\<-\\> Generic\r\n\r\nGenerally specialized code can call generic functions or methods of\r\nobjects that are not statically known (e.g. \"an instance of A or some\r\nsubtype\"). The specialized code will need to box arguments in order to\r\napply such a function. This means that generic wrapper classes need to\r\nbe available for specialized code. For parameterized types this means we\r\nget a different generic class for every different combination of\r\nparameters of that type.\r\n\r\nWe may further allow syntax to store generic objects in specialized\r\nclasses, e.g.\r\n\r\n```python\r\n@jit\r\nclass MyClass(object):\r\n    layout = [('+A[]', 'obj')]\r\n```\r\n\r\nWhich indicates we can store a generic instance of \\`A\\` or any subtype\r\nin the \\`obj\\` slot.\r\n\r\n### Specialized \\<-\\> Specialized\r\n\r\nStatic dispatch everywhere.\r\n\r\nVariance\r\n========\r\n\r\nFinally, we return to the issue of variance. For now we disallow subtype\r\nbounds on type variables of parameterized types, allowing only\r\ninvariance on parameters. This avoids the read/write runtime checks that\r\nwould be needed to guarantee type safety, as touched on in\r\n:ref:\\`core\\`.\r\n\r\nFor bonus points, we can allow annotation of variance in the type\r\nsyntax, allowing more generic code over containers without excessive\r\nruntime type checks:\r\n\r\n```python\r\n@jit('List[+-a]')\r\nclass List(object):\r\n\r\n    @jit('List[a] -> int64 -> +a)\r\n    def __getitem__(self, idx):\r\n        ...\r\n\r\n    @jit('List[a] -> int64 -> -a -> void)\r\n    def __setitem__(self, idx, value):\r\n        ...\r\n```\r\n\r\nThis means that if we substitute a \\`List[b]\\` for a \\`List[a]\\`, then\r\nfor a read operations we have the constraint that \\`b \\<: a\\`, since\r\n\\`b\\` can do everything \\`a\\` does. For a write operation we have that\r\n\\`a \\<: b\\`, since if we are to write objects of type \\`a\\`, then the\r\n\\`b\\` must not be more specific than \\`a\\`.\r\n\r\nThis means the type checker will automatically reject any code that does\r\nnot satisfy the contraints originated by the operations used in the\r\ncode.\r\n% Fusion\r\n% \r\n% \r\n\r\nWe want to fuse operations producing intermediate structures such as\r\nlists or arrays. Fusion or deforestation has been attempted in various\r\nways, we will first cover some of the existing research in the field.\r\n\r\nDeforestation\r\n=============\r\n\r\nbuild/foldr\r\n-----------\r\n\r\nRewrite rules can be used to specify patterns to perform fusion ([1]\\_,\r\n[2]\\_, [3]\\_), e.g.:\r\n\r\n    map f (map g xs) = map (f . g) xs\r\n\r\nThe dot represents the composition operator. To avoid the need for a\r\npattern for each pair of operators, we can express fusable higher-order\r\nfunctions in terms of a small set of combinators. One approach is\r\nbuild/foldr, where `build` generates a list, and `foldr` (reduce)\r\nconsumes it ([3]). Foldr can be defined as follows:\r\n\r\n```haskell\r\nfoldr f z []     = z\r\nfoldr f z (x:xs) = f x (foldr f z xs)\r\n```\r\n\r\n`build` is the dual of `foldr`, instead of reducing a list it generates\r\none. Using just build and foldr, a single rewrite rule can be used for\r\ndeforestation:\r\n\r\n> foldr k z (build g) = g k z\r\n\r\nThis is easy to understand considering that build generates a list, and\r\nfoldr then consumes it, so there's no point in building it in the first\r\nplace. Build is specified as follows:\r\n\r\n```haskell\r\nbuild g (:) []\r\n```\r\n\r\nThis means `g` is applied to the `cons` constructor and the empty list.\r\nWe can define a range function (`from` in [3]) as follows:\r\n\r\n```haskell\r\nrange a b = if a > b then []\r\n            else a : (range (a + 1) b)\r\n```\r\n\r\nAbstracting over cons and nil (the empty list) [3], we get:\r\n\r\n```haskell\r\nrange' a b = \\ f lst -> if a > b then lst\r\n                        else f a (range' (a + 1) b f lst)\r\n```\r\n\r\nIt's easy to see the equivalence to `range` above by substituting `(:)`\r\nfor `f` and `[]` for lst. We can now use `range'` with `build` ([3]):\r\n\r\n```haskell\r\nrange a b = build (range' a b)\r\n```\r\n\r\nThings like `map` can now be expressed as follows ([3]):\r\n\r\n```haskell\r\nmap f xs = build (\\ cons lst -> foldr (\\ a b -> cons (f a) b) lst xs)\r\n```\r\n\r\nHowever, some functions cannot be expressed in this framework, like zip\r\n([4]\\_).\r\n\r\nStreams\r\n-------\r\n\r\nAnother major approach is based on stream fusion ([4]\\_, [5]\\_). It\r\nexpresses the higher-order functions in terms of streams ([4]\\_):\r\n\r\n```haskell\r\nmap f = unstream . map' f . stream\r\n```\r\n\r\n`unstream` converts a stream back to a list, and stream converts a list\r\nto a stream. Under composition, like `map f (map g xs)`, we get\r\n`unsteam . map' f . stream . unsteam . map' g . stream`. The fusion then\r\nrelies on eliminating the composition of `stream` with `unstream`:\r\n\r\n> stream (unstream s) = s\r\n\r\nA stream consists of a stepper function and a state. Stepper functions\r\nproduce new step states. The states are `Done`, `Yield` or `Skip`.\r\n`Done` signals that the stream is consumed, `Yield` yields a new value\r\nand state, and `Skip` signals that a certain value needs to be skipped\r\n(for things like filter).\r\n\r\nLet's see this in action ([5]):\r\n\r\n```haskell\r\nstream :: [a] -> Stream a\r\nstream xs0 = Stream next xs0\r\n    where\r\n        next []     = Done\r\n        next (x:xs) = Yield x xs\r\n```\r\n\r\nThis converts a list to a Stream. It constructs a Stream with a new\r\nstepper function `next` and the initial state (the given list). The\r\n`next` stepper function produces a new step state every time it is\r\ncalled. Streams can be consumed as follows:\r\n\r\n```haskell\r\nmap f (Stream next0 s0) = Stream next s0\r\n    where\r\n        next s = case next0 s of\r\n            Done        -> Done\r\n            Skip s'     -> Skip s'\r\n            Yield x s'  -> Yield (f x) s'\r\n```\r\n\r\nHere we specify a new stepper function `next` that, given a state,\r\nadvances the stream it consumes with the new state, and yields new\r\nresults. It wraps this stepper function in a new stream. [5]\\_ further\r\nextends this work to allow operation over various kinds of streams:\r\n\r\n> -   Chunked streams for bulk memory operations\r\n> -   Vector (multi) streams for SIMD computation\r\n> -   Normal streams that yield one value at a time\r\n\r\nIt bundles the various streams together in a product type. The idea is\r\nthat all streams are available at the same time. Hence a producer can\r\nproduce in the most efficient way, and the consumer can consume in the\r\nmost efficient way. These concepts don't always align, in which case\r\nfallbacks are in place, for instance a chunked stream can be processed\r\nas a scalar stream, or vice-versa. In addition to inlining and other\r\noptimizations it relies heavily on call-pattern specialization ([6]),\r\nallowing the compiler to eliminate pattern matching of consumer sites.\r\n\r\nFusion in flypy\r\n===============\r\n\r\nThe concept of a stream encapsulating a state and a stepper function is\r\nakin to iterators in Python, where the state is part of the iterator and\r\nthe stepping functionality is provided by the `__next__` method.\r\nAlthough iterators can be composed and specialized on static callee\r\ndestination ( the \\_\\_next\\_\\_ method of another iterator), they are\r\nmost naturally expressed as generators:\r\n\r\n    def map(f, xs):\r\n        for x in xs:\r\n            yield f(xs)\r\n\r\nThe state is naturally captured in the generator's stack frame. To allow\r\nfusion we need to inline producers into consumers. This is possible only\r\nif we can turn the lazy generator into a non-lazy producer, i.e. the\r\nconsumer must immediately consume the result. This introduces a\r\nrestriction:\r\n\r\n> -   The generator may not be stored, passed to other functions or\r\n>     returned. We can capture this notion by having `iter(generator)`\r\n>     create a `stream`, and disallowing the rewrite rule\r\n>     `stream (unstream s) = s` to trigger when the `unstream` has\r\n>     multiple uses.\r\n>\r\n>     This means the value remains \\`unstreamed\\` (which itself is lazy,\r\n>     but effectively constitutes a fusion boundary).\r\n>\r\nSince we can express many (all?) higher-order fusable functions as\r\ngenerator, we have a powerful building block (in the same way as the\r\npreviously outlined research methods), that will give us rewrite rules\r\nfor free. I.e., we will not need to state the following:\r\n\r\n```python\r\nmap(f, map(g, xs)) = map(f . g, xs)\r\n```\r\n\r\nsince this automatically follows from the definition of map:\r\n\r\n```python\r\n@signature('(a -> b) -> Stream a -> Stream b')\r\ndef map(f, xs):\r\n    for x in xs:\r\n        yield f(x)\r\n```\r\n\r\nThe two things that need to be addressed are 1) how to inline generators\r\nand 2) how do we specialize on argument \"sub-terms\".\r\n\r\n1. Inlining Generators\r\n======================\r\n\r\nThe inlining pattern is straightforward:\r\n\r\n> -   remove the loop back-edge\r\n> -   promote loop index to stack variable\r\n> -   inline generator\r\n> -   transform 'yield val' to 'i = val'\r\n> -   replace each 'yield' from the callee with a copy of the loop body\r\n>     of the caller\r\n\r\nNow consider a set of generators that have multiple yield expressions:\r\n\r\n```python\r\ndef f(x):\r\n    yield x\r\n    yield x\r\n```\r\n\r\nInlining of the producer into the consumer means duplicating the body\r\nfor each yield. This can lead to exponential code explosion in the size\r\nof the depth of the terms:\r\n\r\n```python\r\nfor i in f(f(f(x))):\r\n    print i\r\n```\r\n\r\nWill result in a function with 8 print statements. However, it is not\r\nalways possible to generate static code without multiple yields,\r\nconsider the concatenation function:\r\n\r\n```python\r\ndef concat(xs, ys):\r\n    for x in xs:\r\n        yield x\r\n    for y in ys:\r\n        yield ys\r\n```\r\n\r\nThis function has two yields. If we rewrite it to use only one yield:\r\n\r\n```python\r\ndef concat(xs, ys):\r\n    for g in (xs, ys):\r\n        for x in g:\r\n            yield x\r\n```\r\n\r\nWe have introduced dynamicity that cannot be eliminated without\r\nspecialization on the values (i.e. unrolling the outer loop, yielding\r\nthe first implementation). This not special in any way, it is inherent\r\nto inlining and we and treat it as such (by simply using an inlining\r\nthreshold). Crossing the threshold simply means temporaries are not\r\neliminated -- in this case this means generator \"cells\" remain.\r\n\r\nIf this proves problematic, functions such as concat can instead always\r\nunstream their results. Even better than fully unstreaming, or sticking\r\nwith a generator cell, is to use a buffering generator fused with the\r\nexpression that consumes N iterations and buffers the results. This\r\ndivides the constant overhead of generators by a constant factor.\r\n\r\n2. Specialization\r\n-----------------\r\n\r\nSpecialization follows from inlining, there are two cases:\r\n\r\n> -   internal terms\r\n> -   boundary terms\r\n> -   `stream (unstream s)` is rewritten, the result is fused\r\n\r\nInternal terms are rewritten according to the `stream (unstream s)`\r\nrule. What eventually follows at a boundary is a) consumption through a\r\nuser-written loop or b) consumption through the remaining unstream. In\r\neither case the result is consumed, and the inliner will start inlining\r\ntop-down (reducing the terms top-down).\r\n\r\nSIMD Producers\r\n==============\r\n\r\nFor simplicity we exclude support for chunked streams. Analogous to\r\n[5]\\_ we can expose a SIMD vector type to the user. This vector can be\r\nyielded by a producer to a consumer.\r\n\r\nHow then, does a consumer pick which stream to operate on? For instance,\r\nzip can only efficiently be implemented if both inputs are the same, not\r\nif one returns vectors and the other scalars (or worse, switching back\r\nand forth mid-way):\r\n\r\n```python\r\ndef zip(xs, ys):\r\n    while True:\r\n        try:\r\n            yield (next(xs), next(ys))\r\n        except StopIteration:\r\n            break\r\n```\r\n\r\nFor functions like zip, which are polymorphic in their arguments, we can\r\nsimply constrain our inputs:\r\n\r\n```python\r\n@overload('Stream[Vector a] -> Stream[Vector b] -> Stream[(Vector a, Vector b)]')\r\n@overload('Stream a -> Stream b -> Stream (a, b)')\r\ndef zip(xs, ys):\r\n    ...\r\n```\r\n\r\nOf course, this means if one of the arguments produces vectors, and the\r\nother scalars, we need to convert one to the other:\r\n\r\n```python\r\n@overload('Stream[Vector a] -> Stream a')\r\ndef convert(stream):\r\n    for x in stream:\r\n        yield x\r\n```\r\n\r\nWhich basically unpacks values from the SIMD register.\r\n\r\nAlternatively, a mixed stream of vectors and scalars can be consumed.\r\n[5]\\_ distinguises between two vector streams:\r\n\r\n> -   a producer stream, which can yield Vector | Scalar\r\n> -   a consumer stream, where the consumer chooses whether to read\r\n>     vectors or scalars. A consumer can start with vectors, and when\r\n>     the vector stream is consumed read from the scalar stream.\r\n\r\nA producer stream is useful for producers that mostly yield vectors, but\r\nsometimes need to yield a few scalars. This class includes functions\r\nlike concat that concatenates two streams, or e.g. a stream over a\r\nmulti-dimensional array where inner-contiguous dimensions have a number\r\nof elements not 0 modulo the vector size.\r\n\r\nA consumer stream on the other hand is useful for functions like zip,\r\nallowing them to vectorize part of the input. However, this does not\r\nseem terribly useful for multi-dimensional arrays with contiguous rows,\r\nwhere it would only vectorize the first row and then fall back to\r\nscalarized code.\r\n\r\nHowever, neither model really makes sense for us, since we would already\r\nmanually specialize our loops:\r\n\r\n```python\r\n@overload('Array a 2 -> Stream a')\r\ndef stream_array(array, vector_size):\r\n    for row in array:\r\n        for i in range(len(row) / vector_size):\r\n            yield load_vector(row.data + i * 4)\r\n\r\n        for i in range(i * 4, len(row)):\r\n            yield row[i]\r\n```\r\n\r\nThis means code consuming scalars and code consuming vectors can be\r\nmatched up through pattern specialiation (which is not just type-based\r\nbranch pruning).\r\n\r\nTo keep things simple, we will stick with a producer stream, yielding\r\neither vectors or scalars. Consumers then pattern-match on the produced\r\nvalues, and pattern specialization can then switch between the two\r\nalternatives:\r\n\r\n```python\r\ndef sum(xs):\r\n    vzero = Vector(zero)\r\n    zero = 0\r\n    for x in xs:\r\n        if isinstance(x, Vector):\r\n            vzero += x\r\n        else:\r\n            zero += x\r\n    return zero + vreduce(add, vzero)\r\n```\r\n\r\nTo understand pattern specialization, consider `xs` is a\r\n`stream_array(a)`. This results in approximately the following code\r\nafter inlining:\r\n\r\n```python\r\nstream_array(array, vector_size):\r\n    for row in array:\r\n        for i in range(len(row) / vector_size):\r\n            x = load_vector(row.data + i * 4)\r\n            if isinstance(x, Vector):\r\n                vzero += x\r\n            else:\r\n                zero += x\r\n\r\n        for i in range(i * 4, len(row)):\r\n            x = row[i]\r\n            if isinstance(x, Vector):\r\n                vzero += x\r\n            else:\r\n                zero += x\r\n```\r\n\r\nIt is now easy to see that we can eliminate the second pattern in the\r\nfirst loop, and the first pattern in the second loop.\r\n\r\nCompiler Support\r\n================\r\n\r\nTo summarize, to support fusion in a general and pythonic way can be\r\nmodelled on generators. To support this we need:\r\n\r\n> -   generator inlining\r\n> -   For SIMD and bulk operations, call pattern specialization. For us\r\n>     this means branch pruning and branch merging based on type.\r\n\r\nThe most important optimization is the fusion, SIMD is a useful\r\nextension. Depending on the LLVM vectorizer (or possibly our own), it\r\nmay not be necessary.\r\n\r\nReferences\r\n==========\r\n% Typing\r\n% \r\n% \r\n\r\nThis section discusses typing for flypy. There is plenty of literature\r\non type inference, most notable is the Damas-Hindley-Milner Algorithm W.\r\nfor lambda calculus [1]\\_, and an extension for ML. The algorithm\r\nhandles let-polymorphism (a.k.a. ML-polymorphism), a form of parametric\r\npolymorphism where type variables themselves may not be polymorphic. For\r\nexample, consider:\r\n\r\n```python\r\ndef f(g, x):\r\n    g(x)\r\n    g(0)\r\n```\r\n\r\nWe can call `f` with a function, which must accept `x` and an value of\r\ntype int. Since `g` is a monotype in `f`, the second call to `g`\r\nrestricts what we accept for `x`: it must be something that promotes\r\nwith an integer. In other words, the type for `g` is `a -> b` and not\r\n`âˆ€a,b.a -> b`.\r\n\r\nAlthough linear in practise, the algorithm's worst case behaviour is\r\nexponential ([2]\\_), since it does not share results for different\r\nfunction invocations. The cartesian product algorithm ([3]\\_) avoids\r\nthis by sharing monomorphic template instantiations. It considers all\r\npossible receivers of a message send, and takes the union of the results\r\nof all instances of the cartesian product substitution. The paper does\r\nnot seem to address circular type dependencies, where the receiver can\r\nchange based on the input types:\r\n\r\n```python\r\ndef f(x):\r\n    for i in range(10):\r\n        x = g(x)\r\n```\r\n\r\nleading to\r\n\r\n```llvm\r\ndefine void f(X0 %x0) {\r\ncond:\r\n    %0 = lt %i 10\r\n    cbranch %0 body exit\r\n\r\nbody:\r\n    %x1 = phi(x0, x2)\r\n    %x2 = call g(%x0)\r\n    br cond\r\n\r\nexit:\r\n    ret void\r\n}\r\n```\r\n\r\nHowever, this can be readily solved through fix-point iteration. If we\r\nassign type variables throughout the function first, we get the\r\nfollowing constraints:\r\n\r\n    [ X1 = Union(X0, X2), G = X1 -> T2 , X2 = T2 ]\r\n\r\nWe can represent a function as a set of overloaded signatures. However,\r\nthe function application is problematic, since we send X1 (which will be\r\nassigned a union type). WIthout using the cartesian product this would\r\nlead to exponential behaviour since there are 2\\^N subsets for N types.\r\n\r\nType inference in flypy\r\n=======================\r\n\r\nWe use the cartesian product algorithm on a constraint network based on\r\nthe dataflow graph. To understand it, we need to understand the input\r\nlanguage. Since we put most functionality of the language in the\r\nuser-domain, we desugar operator syntax through special methods, and we\r\nfurther support overloaded functions.\r\n\r\nThe front-end generates a simple language that can conceptually be\r\ndescribed through the syntax below:\r\n\r\n    e = x                           variable\r\n      | x = a                       assignment\r\n      | const(x)                    constants\r\n      | x.a                         attribute\r\n      | f(x)                        application\r\n      | jump/ret/exc_throw/...      control flow\r\n      | (T) x                       conversion\r\n\r\nAs you'll notice, there are no operators, loops, etc. Control flow is\r\nencoded through jumps, exception raising, return, etc. Loops can be\r\nreadily detected through a simple analysis (see\r\npykit/analysis/loop\\_detection.py).\r\n\r\nWe take this input grammar and generate a simpler constraint network,\r\nthat looks somewhat like this:\r\n\r\n    e = x.a             attribute\r\n      | f(x)            application\r\n      | flow(a, b)      data flow\r\n\r\nThis is a directed graph where each node classifies the constraint on\r\nthe inputs. Types propagate through this network until no more changes\r\ncan take place. If there is an edge `A -> B`, then whenever `A` is\r\nupdated, types are propagated to `B` and processed according to the\r\nconstraint on `B`. E.g. if `B` is a function call, and `A` is an input\r\nargument, we analyze the function call with the new values in the\r\ncartesian product.\r\n\r\nCoercions\r\n=========\r\n\r\nCoercions may happen in two syntactic constructs:\r\n\r\n> -   application\r\n> -   control flow merges (phi nodes)\r\n\r\nFor application we have a working implementation in Blaze that\r\ndetermines the best match for polymorphic type signatures, and allows\r\nfor coercions. For control flow merges, the user can choose whether to\r\npromote values, or whether to create a sum-type. A post-pass can simply\r\ninsert coercions where argument types do not match parameter types.\r\n\r\nSubtyping\r\n=========\r\n\r\nWe intend to support subtyping in the runtime through python\r\ninheritance. When a class B inherits from a class A, we check for a\r\ncompatible interface for the methods (argument types are contravariant\r\nand return types covariant). When typing, the only thing we need to\r\nimplement are coercion and unification:\r\n\r\n> Type B coerces to type A if B is a subtype of A Type A coerces to type\r\n> B if B is a subtype of A with a runtime check only\r\n\r\nThen class types A and B unify iff A is a subtype of B or vice-versa.\r\nThe result of unification is always the supertype.\r\n\r\nFinally, parameteric types will be classified invariant, to avoid\r\nunintended mistakes in the face of mutable containers. Consider e.g.\r\nsuperclass `A` and subclass `B`. Assume we have the function that\r\naccepts an argument typed `A[:]`. If we treat the dtype as covariant,\r\nthen we may pass an array `B[:]` for that argument. However, the code\r\ncan legally write `A`s into the array, violating the rule that we can\r\nonly assign subtypes. The problem is that reading values is covariant,\r\nwhereas writing is contravariant. In other words, the parameter must be\r\ncovariant as well as contravariant at the same time, which is only\r\nsatisfied when `A = B`.\r\n\r\nThe exception is maybe function types, for which we have built-in\r\nvariance rules.\r\n\r\nParameterization\r\n================\r\n\r\nTypes can only be parameterized by variables and user-defined or\r\nbuilt-in types.\r\n\r\nReferences\r\n==========\r\n% flypy Runtime\r\n% \r\n% \r\n\r\nNearly all built-in data types are implemented in the runtime.\r\n\r\nGarbage Collector\r\n=================\r\n\r\nTo support mutable heap-allocated types, we need a garbage collector. To\r\nget started quickly we can use Boehm or reference counting. We will want\r\nto port one of the available copying collectors and use a shadowstack or\r\na lazy pointer stack (for bonus points). The GC should then be local to\r\neach thread, since there is no shared state between threads (only owned\r\nand borrowed data is allowed).\r\n\r\nGarbage collection is abstracted by pykit.\r\n\r\nExceptions\r\n==========\r\n\r\nExceptions are also handled by pykit. We can implement several models,\r\ndepending on the target architecture:\r\n\r\n> -   costful (error return codes)\r\n>     :   -   This will be used on the GPU\r\n>\r\n> -   zero-cost\r\n>     :   -   This should be used where supported. We will start with\r\n>             costful\r\n>\r\n> -   setjmp/longjmp\r\n>     :   -   This will need to happen for every stack frame in case of\r\n>             a shadow stack\r\n>\r\nLocal exception handling will be translated to jumps. This is not\r\ncontrived, since we intend to make heavy use of inlining:\r\n\r\n```python\r\nwhile 1:\r\n    try:\r\n        i = x.__next__()\r\n    except StopIteration:\r\n        break\r\n```\r\n\r\n`x.__next__()` may be inlined (and will be in many instances, like\r\nrange()), and the `raise StopIteration` will be translated to a jump.\r\nControl flow simplification can further optimize the extra jump (jump to\r\nbreak, break to loop exit).\r\n\r\nThreads\r\n=======\r\n\r\nAs mentioned in the core language overview, memory is not shared unless\r\nborrowed. This process is unsafe and correctness must be ensured by the\r\nuser. Immutable data can be copied over channels between threads. Due to\r\na thread-local GC, all threads can run at the same time and allocate\r\nmemory at the same time.\r\n\r\nWe will remove prange and simply use a parallel map with a closure.\r\n\r\nExtension Types\r\n===============\r\n\r\nExtension types are currently built on top of CPython objects. This\r\nshould be avoided. We need to decouple flypy with anything CPython, for\r\nthe sake of portability as well as pycc.\r\n\r\nExtension types can also easily be written in the runtime:\r\n\r\n> -   `unify()` needs to return the supertype or raise a type error\r\n> -   `convert(obj, Object)` needs to do a runtime typecheck\r\n> -   `coerce_distance` needs to return a distance for how far the\r\n>     supertype is up the inheritance tree\r\n\r\nThe approach is simple: generate a wrapper method for each method in the\r\nextension type that does a vtable lookup.\r\n\r\nClosures\r\n========\r\n\r\nThis time we will start with the most common case: closures consumed as\r\ninner functions. This means we don't need dynamic binding for our cell\r\nvariables, and we can do simple lambda lifting instead of complicated\r\nclosure conversion. This also trivially works on the GPU, allowing one\r\nto use map, filter etc, with lambdas trivially.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}